{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "id": "U_jJm2XpxrL2"
      },
      "source": [
        "# Hedonic Pricing\n",
        "\n",
        "We often try to predict the price of an asset from its observable characteristics. This is generally called **hedonic pricing**: How do the unit's characteristics determine its market price?\n",
        "\n",
        "In the lab folder, there are three options: housing prices in pierce_county_house_sales.csv, car prices in cars_hw.csv, and airbnb rental prices in airbnb_hw.csv. If you know of another suitable dataset, please feel free to use that one.\n",
        "\n",
        "1. Clean the data and perform some EDA and visualization to get to know the data set.\n",
        "2. Transform your variables --- particularly categorical ones --- for use in your regression analysis.\n",
        "3. Implement an ~80/~20 train-test split. Put the test data aside.\n",
        "4. Build some simple linear models that include no transformations or interactions. Fit them, and determine their RMSE and $R^2$ on the both the training and test sets. Which of your models does the best?\n",
        "5. Include transformations and interactions, and build a more complex model that reflects your ideas about how the features of the asset determine its value. Determine its RMSE and $R^2$ on the training and test sets. How does the more complex model your build compare to the simpler ones?\n",
        "6. Summarize your results from 1 to 5. Have you learned anything about overfitting and underfitting, or model selection?\n",
        "7. If you have time, use the sklearn.linear_model.Lasso to regularize your model and select the most predictive features. Which does it select? What are the RMSE and $R^2$? We'll cover the Lasso later in detail in class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/itisesha/labs"
      ],
      "metadata": {
        "id": "2_IRDMd1xvOf",
        "outputId": "a912739c-9759-43f5-c155-7e60521b361c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'labs'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 107 (delta 40), reused 43 (delta 24), pack-reused 37 (from 1)\u001b[K\n",
            "Receiving objects: 100% (107/107), 21.09 MiB | 8.61 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n",
            "Updating files: 100% (27/27), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/labs/04_hedonic_pricing/airbnb_hw.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display basic information and the first few rows of the dataset for initial inspection\n",
        "df.info(), df.head()\n"
      ],
      "metadata": {
        "id": "2wnykjgW_GVx",
        "outputId": "542f7d8f-f792-4bd4-fe54-ec47c96299d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30478 entries, 0 to 30477\n",
            "Data columns (total 13 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   Host Id                     30478 non-null  int64  \n",
            " 1   Host Since                  30475 non-null  object \n",
            " 2   Name                        30478 non-null  object \n",
            " 3   Neighbourhood               30478 non-null  object \n",
            " 4   Property Type               30475 non-null  object \n",
            " 5   Review Scores Rating (bin)  22155 non-null  float64\n",
            " 6   Room Type                   30478 non-null  object \n",
            " 7   Zipcode                     30344 non-null  float64\n",
            " 8   Beds                        30393 non-null  float64\n",
            " 9   Number of Records           30478 non-null  int64  \n",
            " 10  Number Of Reviews           30478 non-null  int64  \n",
            " 11  Price                       30478 non-null  object \n",
            " 12  Review Scores Rating        22155 non-null  float64\n",
            "dtypes: float64(4), int64(3), object(6)\n",
            "memory usage: 3.0+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              "     Host Id Host Since                                Name Neighbourhood   \\\n",
              " 0   5162530        NaN     1 Bedroom in Prime Williamsburg       Brooklyn   \n",
              " 1  33134899        NaN     Sunny, Private room in Bushwick       Brooklyn   \n",
              " 2  39608626        NaN                Sunny Room in Harlem      Manhattan   \n",
              " 3       500  6/26/2008  Gorgeous 1 BR with Private Balcony      Manhattan   \n",
              " 4       500  6/26/2008            Trendy Times Square Loft      Manhattan   \n",
              " \n",
              "   Property Type  Review Scores Rating (bin)        Room Type  Zipcode  Beds  \\\n",
              " 0     Apartment                         NaN  Entire home/apt  11249.0   1.0   \n",
              " 1     Apartment                         NaN     Private room  11206.0   1.0   \n",
              " 2     Apartment                         NaN     Private room  10032.0   1.0   \n",
              " 3     Apartment                         NaN  Entire home/apt  10024.0   3.0   \n",
              " 4     Apartment                        95.0     Private room  10036.0   3.0   \n",
              " \n",
              "    Number of Records  Number Of Reviews Price  Review Scores Rating  \n",
              " 0                  1                  0   145                   NaN  \n",
              " 1                  1                  1    37                   NaN  \n",
              " 2                  1                  1    28                   NaN  \n",
              " 3                  1                  0   199                   NaN  \n",
              " 4                  1                 39   549                  96.0  )"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the data\n",
        "\n",
        "# Remove any non-numeric characters (like $ or ,) from the Price column and convert it to numeric\n",
        "df['Price'] = df['Price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
        "\n",
        "# Handle missing values - we'll fill missing numeric columns with median values and categorical ones with mode\n",
        "df['Host Since'] = pd.to_datetime(df['Host Since'], errors='coerce')  # Convert 'Host Since' to datetime\n",
        "df['Host Since'].fillna(df['Host Since'].median(), inplace=True)\n",
        "\n",
        "# Fill missing numerical values with the median\n",
        "df['Review Scores Rating (bin)'].fillna(df['Review Scores Rating (bin)'].median(), inplace=True)\n",
        "df['Review Scores Rating'].fillna(df['Review Scores Rating'].median(), inplace=True)\n",
        "df['Beds'].fillna(df['Beds'].median(), inplace=True)\n",
        "df['Zipcode'].fillna(df['Zipcode'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns that may not be useful for regression (Host Id, Name, Number of Records)\n",
        "df_cleaned = df.drop(['Host Id', 'Name', 'Number of Records'], axis=1)\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "df_cleaned = pd.get_dummies(df_cleaned, columns=['Neighbourhood', 'Property Type', 'Room Type'], drop_first=True)\n",
        "\n",
        "# Splitting the data into features (X) and target (y)\n",
        "X = df_cleaned.drop(columns=['Price'])\n",
        "y = df_cleaned['Price']\n",
        "\n",
        "# Perform 80/20 train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the cleaned data and shapes of the splits\n",
        "df_cleaned.head(), X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "id": "u_W-YzWs_Rjc",
        "outputId": "44c4b7c6-b67f-4c4e-95f0-96a4b1c03508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-37a24348fe2e>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Host Since'].fillna(df['Host Since'].median(), inplace=True)\n",
            "<ipython-input-3-37a24348fe2e>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Review Scores Rating (bin)'].fillna(df['Review Scores Rating (bin)'].median(), inplace=True)\n",
            "<ipython-input-3-37a24348fe2e>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Review Scores Rating'].fillna(df['Review Scores Rating'].median(), inplace=True)\n",
            "<ipython-input-3-37a24348fe2e>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Beds'].fillna(df['Beds'].median(), inplace=True)\n",
            "<ipython-input-3-37a24348fe2e>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Zipcode'].fillna(df['Zipcode'].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Neighbourhood'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-37a24348fe2e>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# One-hot encode categorical variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Neighbourhood'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Property Type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Room Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Splitting the data into features (X) and target (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/encoding.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be a list-like for parameter `columns`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mdata_to_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Neighbourhood'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import necessary libraries since they were not loaded after the error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Perform 80/20 train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the shapes of the cleaned data and the train-test split\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "id": "0_zdWEou_VaI",
        "outputId": "9e2215c4-2209-4efd-cb73-835b7f733738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1ac319c692de>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Perform 80/20 train-test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Check the shapes of the cleaned data and the train-test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on training and test sets\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE and R2 for training and test sets\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "train_rmse, test_rmse, train_r2, test_r2\n"
      ],
      "metadata": {
        "id": "IEhMSxMh_ZEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'Host Since' column since it's not usable in the regression model\n",
        "X = X.drop(columns=['Host Since'])\n",
        "\n",
        "# Perform the train-test split again after dropping the column\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the linear regression model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on training and test sets\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE and R2 for training and test sets\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "train_rmse, test_rmse, train_r2, test_r2\n"
      ],
      "metadata": {
        "id": "bQupqjyy_gsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefining the train-test split and necessary imports due to environment reset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset again\n",
        "file_path = '/mnt/data/airbnb_hw.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Clean the data: remove non-numeric characters from 'Price', handle missing values, etc.\n",
        "df['Price'] = df['Price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
        "df['Host Since'] = pd.to_datetime(df['Host Since'], errors='coerce')\n",
        "df['Host Since'].fillna(df['Host Since'].median(), inplace=True)\n",
        "df['Review Scores Rating (bin)'].fillna(df['Review Scores Rating (bin)'].median(), inplace=True)\n",
        "df['Review Scores Rating'].fillna(df['Review Scores Rating'].median(), inplace=True)\n",
        "df['Beds'].fillna(df['Beds'].median(), inplace=True)\n",
        "df['Zipcode'].fillna(df['Zipcode'].mode()[0], inplace=True)\n",
        "df_cleaned = df.drop(['Host Id', 'Name', 'Number of Records'], axis=1)\n",
        "\n",
        "# Strip whitespaces and perform one-hot encoding\n",
        "df_cleaned.columns = df_cleaned.columns.str.strip()\n",
        "df_cleaned = pd.get_dummies(df_cleaned, columns=['Neighbourhood', 'Property Type', 'Room Type'], drop_first=True)\n",
        "\n",
        "# Drop 'Host Since' column and define X and y\n",
        "X = df_cleaned.drop(columns=['Host Since', 'Price'])\n",
        "y = df_cleaned['Price']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Polynomial Features (degree=2 for interaction terms)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Fit and evaluate complex linear regression model\n",
        "model_poly = LinearRegression()\n",
        "model_poly.fit(X_train_poly, y_train)\n",
        "\n",
        "# Predict on train and test sets\n",
        "y_train_poly_pred = model_poly.predict(X_train_poly)\n",
        "y_test_poly_pred = model_poly.predict(X_test_poly)\n",
        "\n",
        "# Calculate RMSE and R2\n",
        "train_rmse_poly = np.sqrt(mean_squared_error(y_train, y_train_poly_pred))\n",
        "test_rmse_poly = np.sqrt(mean_squared_error(y_test, y_test_poly_pred))\n",
        "\n",
        "train_r2_poly = r2_score(y_train, y_train_poly_pred)\n",
        "test_r2_poly = r2_score(y_test, y_test_poly_pred)\n",
        "\n",
        "train_rmse_poly, test_rmse_poly, train_r2_poly, test_r2_poly\n"
      ],
      "metadata": {
        "id": "1qHDSvNP_uM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This suggests that the more complex model may be overfitting, as its performance on the test set deteriorated, which demonstrates the trade-off between model complexity and generalizability. â€‹"
      ],
      "metadata": {
        "id": "w0PSSi3u_3H_"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}